Part 1 LLM 소개
Chapter 1 LLM
_1.1 LLM이란?
__1.1.1 LLM 정의
__1.1.2 LLM 주요 특징
__1.1.3 LLM 작동 원리
_1.2 현재 많이 사용되는 LLM
__1.2.1 BERT
__1.2.2 GPT-4와 ChatGPT
__1.2.3 T5
_1.3 도메인 특화 LLM
_1.4 LLM을 이용한 애플리케이션
__1.4.1 전통적인 자연어 처리(NLP) 작업
__1.4.2 자유로운 텍스트 생성
__1.4.3 정보 검색/신경망 의미 기반 검색
__1.4.4 챗봇
_1.5 마치며

Chapter 2 LLM을 이용한 의미 기반 검색
_2.1 들어가는 글
_2.2 작업
__2.2.1 비대칭적 의미 기반 검색
_2.3 솔루션 개요
_2.4 구성 요소
__2.4.1 텍스트 임베더
__2.4.2 문서 청킹
__2.4.3 벡터 데이터베이스
__2.4.4 파인콘
__2.4.5 오픈 소스 대안
__2.4.6 검색 결과 재순위화
__2.4.7 API
_2.5 통합
__2.5.1 성능
_2.6 클로즈드 소스 구성 요소의 비용
_2.7 마치며

Chapter 3 프롬프트 엔지니어링의 첫 번째 단계
_3.1 들어가는 글
_3.2 프롬프트 엔지니어링
__3.2.1 언어 모델에서 정렬
__3.2.2 직접 요청하기
__3.2.3 퓨샷 학습
__3.2.4 출력 구조화
__3.2.5 페르소나 지정하기
_3.3 여러 모델과 프롬프트 작업하기
__3.3.1 ChatGPT
__3.3.2 Cohere
__3.3.3 오픈 소스 프롬프트 엔지니어링
_3.4 ChatGPT와 Q/A 챗봇 만들기
_3.5 마치며

Part 2 LLM 활용법
Chapter 4 맞춤형 파인튜닝으로 LLM을 최적화하기
_4.1 들어가는 글
_4.2 파인튜닝과 전이학습: 기초 안내서
__4.2.1 파인튜닝 과정
__4.2.2 파운데이션 모델로 사전 훈련된 클로즈드 소스 모델 사용하기
_4.3 OpenAI 파인튜닝 API 살펴보기
__4.3.1 GPT-3 파인튜닝 API
__4.3.2 사례 연구: Amazon 리뷰 감정 분류
__4.3.3 데이터에 대한 지침 및 모범 사례
_4.4 OpenAI CLI로 맞춤형 예제 준비하기
_4.5 OpenAI CLI 설정하기
__4.5.1 하이퍼파라미터 선택과 최적화
_4.6 첫 번째 파인튜닝 LLM
__4.6.1 정량적 지표로 파인튜닝 모델 평가하기
__4.6.2 정성적 평가 기술
__4.6.3 파인튜닝된 GPT-3 모델을 애플리케이션에 통합하기
_4.7 사례 연구 2: Amazon 리뷰 카테고리 분류
_4.8 마치며

Chapter 5 고급 프롬프트 엔지니어링
_5.1 들어가는 글
_5.2 프롬프트 인젝션 공격
_5.3 입력/출력 유효성 검사
__5.3.1 예제: NLI 이용해서 유효성 검사 파이프라인 만들기
_5.4 배치 프롬프팅
_5.5 프롬프트 체이닝
__5.5.1 프롬프트 인젝션을 방어하기 위한 체이닝
__5.5.2 프롬프트 스터핑을 막기 위한 체이닝
__5.5.3 예제: 멀티모달 LLM을 안전하게 사용하기 위한 체이닝
_5.6 연쇄적 사고 프롬프트
__5.6.1 예시: 기초 연산
_5.7 퓨샷 학습 다시 보기
__5.7.1 예제: LLM을 이용한 초등학교 수학
_5.8 테스트와 반복적 프롬프트 개발
_5.9 마치며

Chapter 6 임베딩과 모델 아키텍처 맞춤화
_6.1 들어가는 글
_6.2 사례 연구: 추천 시스템 만들기
__6.2.1 문제와 데이터 설정하기
__6.2.2 추천의 문제 정의하기
__6.2.3 추천 시스템의 전체 개요
__6.2.4 항목 비교를 위한 맞춤형 설명 필드 생성
__6.2.5 파운데이션 임베더로 기준선 설정
__6.2.6 파인튜닝 데이터 준비
__6.2.7 문장 트랜스포머 라이브러리로 오픈 소스 임베더 파인튜닝하기
__6.2.8 결과 요약
_6.3 마치며

Part 3 고급 LLM 사용법
Chapter 7 파운데이션 모델을 넘어서
_7.1 들어가는 글
_7.2 사례연구: VQA
__7.2.1 모델 소개: ViT, GPT-2 및 DistillBERT
__7.2.2 은닉 상태 투영과 융합
__7.2.3 크로스-어텐션: 이것은 무엇이며 왜 중요한가요?
__7.2.4 맞춤형 멀티모달 모델
__7.2.5 데이터: Visual QA
__7.2.6 VQA 훈련 과정
__7.2.7 결과 요약
_7.3 사례 연구: 피드백 기반 강화 학습
__7.3.1 모델: FLAN-T5
__7.3.2 보상 모델: 감정과 문법 정확도
__7.3.3 트랜스포머 강화 학습
__7.3.4 RLF 훈련 과정
__7.3.5 결과 요약
_7.4 마치며

Chapter 8 고급 오픈 소스 LLM 파인튜닝
_8.1 들어가는 글
_8.2 예시: BERT를 이용한 애니메이션 장르 다중 레이블 분류
__8.2.1 다중 레이블 장르 예측을 위한 성능 측정 지표로 자카드 점수 사용하기
__8.2.2 단순 파인튜닝 과정
__8.2.3 오픈 소스 LLM 파인튜닝을 위한 일반적인 팁
__8.2.4 결과 요약
_8.3 예시: GPT-2를 이용한 LaTeX 생성
__8.3.1 오픈 소스 모델을 위한 프롬프트 엔지니어링
__8.3.2 결과 요약
_8.4 시난의 현명하면서도 매력적인 답변 생성기: SAWYER
__1단계: 지시사항 파인튜닝
__2단계: 보상 모델 훈련
__3단계: (예상하는) 사용자 피드백 기반 강화 학습
__결과 요약
_8.5 끊임없이 변화하는 파인튜닝의 세계
_8.6 마치며

Chapter 9 LLM을 프로덕션 환경에서 사용하기
_9.1 들어가는 글
_9.2 클로즈드 소스 LLM을 프로덕션 환경에 배포하기
__9.2.1 비용 예측
__9.2.2 API 키 관리
_9.3 프로덕션 환경에 오픈 소스 LLM 배포하기
__9.3.1 추론을 위한 모델 준비
__9.3.2 상호 운용성
__9.3.3 양자화
__9.3.4 가지치기
__9.3.5 지식 증류
__9.3.6 LLM 사용에 대한 비용 예측
__9.3.7 Hugging Face에 올리기
_9.4 마치며

Part 4 부록
APPENDIX A LLM 자주 묻는 질문(FAQ)
APPENDIX B LLM 용어 해설
APPENDIX C LLM 애플리케이션 개발 고려사항